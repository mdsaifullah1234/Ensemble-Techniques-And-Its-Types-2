{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  = Bagging reduces overfitting in decision trees by training multiple trees on different subsets of the training data and then averaging their predictions. This helps to reduce the variance of the model and make it more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS  =  Advantages of using different types of base learners in bagging include increased diversity of models, which can lead to better overall performance. Disadvantages may include increased computational complexity and potential difficulty in interpreting the combined model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS =  The choice of base learner in bagging can affect the bias-variance tradeoff. More complex base learners may have lower bias but higher variance, while simpler base learners may have higher bias but lower variance. The ensemble aims to reduce variance by averaging the predictions of multiple base learners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = Yes, bagging can be used for both classification and regression tasks. In classification tasks, bagging involves aggregating the predictions of multiple classifiers (e.g., decision trees) trained on different subsets of the training data. In regression tasks, it involves aggregating the predictions of multiple regression models (e.g., decision trees) trained on different subsets of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = The ensemble size in bagging refers to the number of base learners included in the ensemble. Typically, larger ensemble sizes can lead to better performance, up to a point of diminishing returns. The optimal number of models depends on factors such as the complexity of the problem and computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS = A real-world application of bagging in machine learning is in financial forecasting, where it can be used to combine the predictions of multiple models trained on historical financial data to improve the accuracy of predictions for future market trends or stock prices."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
